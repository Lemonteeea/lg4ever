{"title":"36 | 如何使用 ELK 进行日志采集以及统一处理？","context":"\n                    <p data-nodeid=\"837\" class=\"\">\n                      在前面的一系列课时，我们介绍了微服务各个组件的相关实践，从本课时开始我们将会介绍微服务日常开发的一些“利器”，这些工具会帮助我们构建更加健壮的微服务系统，并帮助排查解决微服务系统中的问题与性能瓶颈等。\n                    </p>\n                    <p data-nodeid=\"838\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/AB/Ciqc1F-WrqCAfyhyAAG2q-6nf6o454.png\"\n                        alt=\"Drawing 0.png\"\n                        data-nodeid=\"923\"\n                      />\n                    </p>\n                    <div data-nodeid=\"839\">\n                      <p style=\"text-align: center\">ELK 技术栈</p>\n                    </div>\n                    <p data-nodeid=\"840\">\n                      本课时将重点介绍<strong data-nodeid=\"929\"\n                        >微服务架构中的日志收集方案 ELK</strong\n                      >（ELK 是 Elasticsearch、Logstash 和 Kibana\n                      的简称），准确地说是 ELKB，即 ELK + Filebeat，其中\n                      Filebeat 是用于转发和集中日志数据的轻量级传送工具。\n                    </p>\n                    <h3 data-nodeid=\"841\">为什么需要分布式日志系统</h3>\n                    <p data-nodeid=\"842\">\n                      在以前的项目中，如果想要在生产环境中通过日志定位业务服务的\n                      Bug\n                      或者性能问题，则需要运维人员使用命令挨个服务实例去查询日志文件，这样导致的结果就是：排查问题的效率非常低。\n                    </p>\n                    <p data-nodeid=\"843\">\n                      在微服务架构中，服务多实例部署在不同的物理机上，各个微服务的日志也被分散储存在不同的物理机。集群足够大的话，使用上述传统的方式查阅日志就变得非常不合适。因此需要集中化管理分布式系统中的日志，其中有开源的组件如\n                      Syslog，用于将所有服务器上的日志收集汇总。\n                    </p>\n                    <p data-nodeid=\"844\">\n                      然而集中化日志文件之后，我们面临的是对这些日志文件进行统计和检索，比如哪些服务有报警和异常，这些都需要有详细的统计。所以，在以前出现线上故障时，经常会看到开发和运维人员下载服务的日志，并基于\n                      Linux 下的一些命令（如 grep、awk 和 wc\n                      等）进行检索和统计。这样的方式不仅工作量大、效率低，而且对于要求更高的查询、排序和统计等操作，以及庞大的机器数量，难免会有点“力不从心”，无法很好地胜任。\n                    </p>\n                    <h3 data-nodeid=\"845\">ELKB 分布式日志系统</h3>\n                    <p data-nodeid=\"846\">\n                      <strong data-nodeid=\"939\"\n                        >ELKB 是一个完整的分布式日志收集系统</strong\n                      >，很好地解决了上述提到的日志收集难、检索和分析难的问题。\n                    </p>\n                    <p data-nodeid=\"847\">\n                      ELKB 分别是指 Elasticsearch、Logstash、Kibana 和\n                      Filebeat。Elastic 提供的一整套组件可以看作是 MVC\n                      模型：Logstash 对应逻辑控制 Controller 层，Elasticsearch\n                      是一个数据模型 Model 层，而 Kibana 则是视图 View\n                      层。Logstash 和 Elasticsearch 是基于 Java\n                      编写实现的，Kibana 则使用的是 Node.js 框架。\n                    </p>\n                    <p data-nodeid=\"848\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/B6/CgqCHl-Wrq-AE2cPAAMTezenVUk045.png\"\n                        alt=\"Drawing 1.png\"\n                        data-nodeid=\"943\"\n                      />\n                    </p>\n                    <div data-nodeid=\"849\">\n                      <p style=\"text-align: center\">ELKB 日志采集系统</p>\n                    </div>\n                    <p data-nodeid=\"850\">\n                      下面我们就来依次介绍这几个组件的功能，以及它们在日志采集系统中的作用。\n                    </p>\n                    <h4 data-nodeid=\"851\">Elasticsearch 的安装与使用</h4>\n                    <p data-nodeid=\"852\">\n                      <strong data-nodeid=\"950\"\n                        >Elasticsearch 是分布式系统中的实时搜索分析引擎</strong\n                      >，使用 Java 语言实现，基于 Apache Lucene\n                      搜索引擎库构建，可以用来进行全文检索、结构化搜索、分析以及这三个功能的组合。Elasticsearch\n                      支持数百个节点的扩展，能够存储 PB 级别的数据。\n                    </p>\n                    <p data-nodeid=\"853\">\n                      另外，Elasticsearch\n                      是面向文档的，它可以存储和搜索整个对象或文档。在\n                      Elasticsearch\n                      中，你可以对整个文档进行索引、检索、排序和过滤，这不同于传统的关系型数据库对行列数据进行操作。\n                    </p>\n                    <p data-nodeid=\"854\">\n                      为了方便，我们直接使用 Docker 安装 Elasticsearch：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">$ docker run -d --name elasticsearch  docker.elastic.co/elasticsearch/elasticsearch:<span class=\"hljs-number\">5.4</span><span class=\"hljs-number\">.0</span>\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"856\">\n                      需要注意的是，Elasticsearch\n                      启动之后需要进行简单的设置，xpack.security.enabled\n                      默认是开启的，但我们为了方便测试，就取消登录认证，将该配置设置为\n                      false。登入容器内部，执行如下的命令：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\"># 进入启动好的容器\n</div></li><li><div class=\"code-word\">$ docker exec -it elasticsearch bash\n</div></li><li><div class=\"code-word\"># 编辑配置文件\n</div></li><li><div class=\"code-word\">$ vim config/elasticsearch.yml\n</div></li><li><div class=\"code-word\">cluster.name: <span class=\"hljs-string\">\"docker-cluster\"</span>\n</div></li><li><div class=\"code-word\">network.host: <span class=\"hljs-number\">0.0</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.0</span>\n</div></li><li><div class=\"code-word\">http.cors.enabled: <span class=\"hljs-keyword\">true</span>\n</div></li><li><div class=\"code-word\">http.cors.allow-origin: <span class=\"hljs-string\">\"*\"</span>\n</div></li><li><div class=\"code-word\">xpack.security.enabled: <span class=\"hljs-keyword\">false</span>\n</div></li><li><div class=\"code-word\"># minimum_master_nodes need to be explicitly <span class=\"hljs-keyword\">set</span> when bound <span class=\"hljs-keyword\">on</span> a public IP\n</div></li><li><div class=\"code-word\"># <span class=\"hljs-keyword\">set</span> to <span class=\"hljs-number\">1</span> to allow single node clusters\n</div></li><li><div class=\"code-word\"># Details: https:<span class=\"hljs-comment\">//github.com/elastic/elasticsearch/pull/17288</span>\n</div></li><li><div class=\"code-word\">discovery.zen.minimum_master_nodes: <span class=\"hljs-number\">1</span>\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"858\">\n                      修改好配置文件之后，退出容器，再重启容器即可完成配置。我们为了后面使用时能够保留配置，就需要从该容器创建一个新的镜像。首先获取到该容器对应的\n                      ContainerId，然后基于该容器提交成一个新的镜像。\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">$ docker commit -a <span class=\"hljs-string\">\"add config\"</span> -m <span class=\"hljs-string\">\"dev\"</span> a404c6c174a2  es:latest\n</div></li><li><div class=\"code-word\">sha256:<span class=\"hljs-number\">5</span>cb8c995ca819765323e76cccea8f55b423a6fa2eecd9c1048b2787818c1a994\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"860\">\n                      这样我们就得到了一个新的镜像 es:latest。我们运行新的镜像：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">docker run -d --name es -p <span class=\"hljs-number\">9200</span>:<span class=\"hljs-number\">9200</span> -p <span class=\"hljs-number\">9300</span>:<span class=\"hljs-number\">9300</span>   -e <span class=\"hljs-string\">\"discovery.type=single-node\"</span> es:latest\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"862\">\n                      通过访问 Elasticsearch 提供的内置端点，我们检查\n                      Elasticsearch 是否安装成功。\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">$ curl <span class=\"hljs-string\">'http://localhost:9200/_nodes/http?pretty'</span>\n</div></li><li><div class=\"code-word\">{\n</div></li><li><div class=\"code-word\">  <span class=\"hljs-string\">\"_nodes\"</span> : {\n</div></li><li><div class=\"code-word\">    <span class=\"hljs-string\">\"total\"</span> : <span class=\"hljs-number\">1</span>,\n</div></li><li><div class=\"code-word\">    <span class=\"hljs-string\">\"successful\"</span> : <span class=\"hljs-number\">1</span>,\n</div></li><li><div class=\"code-word\">    <span class=\"hljs-string\">\"failed\"</span> : <span class=\"hljs-number\">0</span>\n</div></li><li><div class=\"code-word\">  }, #&nbsp;集群大小\n</div></li><li><div class=\"code-word\">  <span class=\"hljs-string\">\"cluster_name\"</span> : <span class=\"hljs-string\">\"docker-cluster\"</span>, # 设置的集群名称\n</div></li><li><div class=\"code-word\">  <span class=\"hljs-string\">\"nodes\"</span> : { #&nbsp;节点的详细信息\n</div></li><li><div class=\"code-word\">    <span class=\"hljs-string\">\"8iH5v9C-Q9GA3aSupm4caw\"</span> : {\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"name\"</span> : <span class=\"hljs-string\">\"8iH5v9C\"</span>,\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"transport_address\"</span> : <span class=\"hljs-string\">\"10.0.1.14:9300\"</span>,\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"host\"</span> : <span class=\"hljs-string\">\"10.0.1.14\"</span>,\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"ip\"</span> : <span class=\"hljs-string\">\"10.0.1.14\"</span>,\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"version\"</span> : <span class=\"hljs-string\">\"5.4.0\"</span>,\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"build_hash\"</span> : <span class=\"hljs-string\">\"780f8c4\"</span>,\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"roles\"</span> : [\n</div></li><li><div class=\"code-word\">        <span class=\"hljs-string\">\"master\"</span>,\n</div></li><li><div class=\"code-word\">        <span class=\"hljs-string\">\"data\"</span>,\n</div></li><li><div class=\"code-word\">        <span class=\"hljs-string\">\"ingest\"</span>\n</div></li><li><div class=\"code-word\">      ],\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"attributes\"</span> : {\n</div></li><li><div class=\"code-word\">        <span class=\"hljs-string\">\"ml.enabled\"</span> : <span class=\"hljs-string\">\"true\"</span>\n</div></li><li><div class=\"code-word\">      },\n</div></li><li><div class=\"code-word\">      <span class=\"hljs-string\">\"http\"</span> : { #&nbsp;绑定的 http 端口\n</div></li><li><div class=\"code-word\">        <span class=\"hljs-string\">\"bound_address\"</span> : [\n</div></li><li><div class=\"code-word\">          <span class=\"hljs-string\">\"[::]:9200\"</span>\n</div></li><li><div class=\"code-word\">        ],\n</div></li><li><div class=\"code-word\">        <span class=\"hljs-string\">\"publish_address\"</span> : <span class=\"hljs-string\">\"10.0.1.14:9200\"</span>,\n</div></li><li><div class=\"code-word\">        <span class=\"hljs-string\">\"max_content_length_in_bytes\"</span> : <span class=\"hljs-number\">104857600</span>\n</div></li><li><div class=\"code-word\">      }\n</div></li><li><div class=\"code-word\">    }\n</div></li><li><div class=\"code-word\">  }\n</div></li><li><div class=\"code-word\">}\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"864\">\n                      可以看到，我们成功安装了\n                      Elasticsearch。另外，为了方便查看数据，我们需要安装\n                      Elasticsearch\n                      的可视化工具：elasticsearch-head。这个安装方法就很简单了：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">$ docker run -p <span class=\"hljs-number\">9100</span>:<span class=\"hljs-number\">9100</span> mobz/elasticsearch-head:<span class=\"hljs-number\">5</span>\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"866\">\n                      elasticsearch-head 是一款 Elasticsearch\n                      可视化工具，能够显示 Elasticsearch\n                      状态，除了数据可视化，还可以执行增、删、改、查等操作。\n                    </p>\n                    <p data-nodeid=\"867\">安装之后的界面如下所示：</p>\n                    <p data-nodeid=\"868\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/B6/CgqCHl-Wrt6AFxP1AA0vHSwXInE125.png\"\n                        alt=\"Drawing 2.png\"\n                        data-nodeid=\"962\"\n                      />\n                    </p>\n                    <div data-nodeid=\"869\">\n                      <p style=\"text-align: center\">elasticsearch-head 界面</p>\n                    </div>\n                    <h4 data-nodeid=\"870\">Logstash 的安装与使用</h4>\n                    <p data-nodeid=\"871\">\n                      Logstash 是一个数据分析软件，主要用于分析 Log\n                      日志。其工作原理如下所示：\n                    </p>\n                    <p data-nodeid=\"872\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/AB/Ciqc1F-WruaAULiSAABppBq55b8500.png\"\n                        alt=\"Drawing 3.png\"\n                        data-nodeid=\"967\"\n                      />\n                    </p>\n                    <div data-nodeid=\"873\">\n                      <p style=\"text-align: center\">Logstash 工作原理图</p>\n                    </div>\n                    <p data-nodeid=\"874\">\n                      数据源首先将数据传给 Logstash（这里我们使用的是 Filebeat\n                      传输日志数据），它主要包括 Input 数据输入、Filter\n                      数据源过滤和 Output 数据输出三部分。\n                    </p>\n                    <p data-nodeid=\"875\">\n                      Logstash\n                      可以对数据进行处理，包括数据的过滤和格式化，之后发送到\n                      Elasticsearch 存储，并在 Elasticsearch 中建立相应的索引。\n                    </p>\n                    <p data-nodeid=\"876\">\n                      下面我们就来安装和使用 Logstash。首先，下载并解压\n                      Logstash：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\"># 下载 logstash\n</div></li><li><div class=\"code-word\">$ wget https:<span class=\"hljs-comment\">//artifacts.elastic.co/downloads/logstash/logstash-5.4.3.tar.gz</span>\n</div></li><li><div class=\"code-word\"># 解压 logstash\n</div></li><li><div class=\"code-word\">$ tar -zxvf logstash<span class=\"hljs-number\">-5.4</span><span class=\"hljs-number\">.3</span>.tar.gz\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"878\">\n                      下载速度可能比较慢，如果你想速度稍微快点，可以选择国内的镜像源。解压成功之后，我们需要配置\n                      Logstash，主要就是我们前面所提到的输入、过滤和输出。\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"powershell\"><ol><li><div class=\"code-word\"><span class=\"hljs-variable\">$</span> vi logstash<span class=\"hljs-literal\">-5</span>.<span class=\"hljs-number\">4.3</span>/client.conf\n</div></li><li><div class=\"code-word\">input {  <span class=\"hljs-comment\"># 输入的设置，使用 filebeat</span>\n</div></li><li><div class=\"code-word\">    beats {\n</div></li><li><div class=\"code-word\">        port =&gt; <span class=\"hljs-number\">5044</span>\n</div></li><li><div class=\"code-word\">        codec =&gt; <span class=\"hljs-string\">\"json\"</span>\n</div></li><li><div class=\"code-word\">    }\n</div></li><li><div class=\"code-word\">}\n</div></li><li><div class=\"code-word\">output { <span class=\"hljs-comment\">#输出到 ES 中</span>\n</div></li><li><div class=\"code-word\">    elasticsearch {\n</div></li><li><div class=\"code-word\">        hosts =&gt; [<span class=\"hljs-string\">\"127.0.0.1:9200\"</span>]\n</div></li><li><div class=\"code-word\">        index =&gt; <span class=\"hljs-string\">\"logstash-app-error-%{+YYYY.MM.dd}\"</span>\n</div></li><li><div class=\"code-word\">    }\n</div></li><li><div class=\"code-word\">    stdout {codec =&gt; rubydebug}\n</div></li><li><div class=\"code-word\">}\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"880\">\n                      <strong data-nodeid=\"976\">输入</strong>支持文件、Syslog 和\n                      Beats，我们在配置时只能选择其中一种。这里我们配置了\n                      Filebeats 方式。\n                    </p>\n                    <p data-nodeid=\"881\">\n                      <strong data-nodeid=\"981\">过滤</strong\n                      >则用于处理一些特定的行为，如匹配特定规则的事件流。常见的\n                      filters 有：geoip 添加地理信息、drop 丢弃部分事件和 mutate\n                      修改文档等。如下是一个 filter 使用的示例：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">filter {\n</div></li><li><div class=\"code-word\">  #定义客户端的 IP 是哪个字段\n</div></li><li><div class=\"code-word\">  geoip {\n</div></li><li><div class=\"code-word\">    source =&gt; <span class=\"hljs-string\">\"clientIp\"</span>\n</div></li><li><div class=\"code-word\">  }\n</div></li><li><div class=\"code-word\">}\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"883\">\n                      <strong data-nodeid=\"986\">输出</strong>支持\n                      Elasticsearch、File、Graphite 和\n                      StatsD，默认情况下将过滤的数据输出到\n                      Elasticsearch，当我们不需要输出到 Elasticsearch\n                      时就需要特别声明输出的方式是哪一种。Logstash\n                      支持同时配置多个输出源。\n                    </p>\n                    <p data-nodeid=\"884\">\n                      我们在配置中，将日志信息输出到\n                      Elasticsearch。配置文件搞定之后，我们开始启动 Logstash：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">$ bin/logstash  -f client.conf\n</div></li><li><div class=\"code-word\">Sending Logstash's logs to /elk/logstash-5.4.3/logs which is now configured via log4j2.properties\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:26,056][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=&gt;{:removed=&gt;[], :added=&gt;[http://127.0.0.1:9200/]}}\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:26,062][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://127.0.0.1:9200/, :path=&gt;\"/\"}\n</div></li><li><div class=\"code-word\">log4j:WARN No appenders could be found for logger (org.apache.http.client.protocol.RequestAuthCache).\n</div></li><li><div class=\"code-word\">log4j:WARN Please initialize the log4j system properly.\n</div></li><li><div class=\"code-word\">log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:26,209][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=&gt;#&lt;URI::HTTP:0x1abac0 URL:http://127.0.0.1:9200/&gt;}[2020-10-12T14:12:26,225][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=&gt;nil}\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:26,288][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=&gt;{\"template\"=&gt;\"logstash-*\", \"version\"=&gt;50001, \"settings\"=&gt;{\"index.refresh_interval\"=&gt;\"5s\"}, \"mappings\"=&gt;{\"_default_\"=&gt;{\"_all\"=&gt;{\"enabled\"=&gt;true, \"norms\"=&gt;false}, \"dynamic_templates\"=&gt;[{\"message_field\"=&gt;{\"path_match\"=&gt;\"message\", \"match_mapping_type\"=&gt;\"string\", \"mapping\"=&gt;{\"type\"=&gt;\"text\", \"norms\"=&gt;false}}}, {\"string_fields\"=&gt;{\"match\"=&gt;\"*\", \"match_mapping_type\"=&gt;\"string\", \"mapping\"=&gt;{\"type\"=&gt;\"text\", \"norms\"=&gt;false, \"fields\"=&gt;{\"keyword\"=&gt;{\"type\"=&gt;\"keyword\"}}}}}], \"properties\"=&gt;{\"@timestamp\"=&gt;{\"type\"=&gt;\"date\", \"include_in_all\"=&gt;false}, \"@version\"=&gt;{\"type\"=&gt;\"keyword\", \"include_in_all\"=&gt;false}, \"geoip\"=&gt;{\"dynamic\"=&gt;true, \"properties\"=&gt;{\"ip\"=&gt;{\"type\"=&gt;\"ip\"}, \"location\"=&gt;{\"type\"=&gt;\"geo_point\"}, \"latitude\"=&gt;{\"type\"=&gt;\"half_float\"}, \"longitude\"=&gt;{\"type\"=&gt;\"half_float\"}}}}}}}}\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:26,304][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=&gt;\"LogStash::Outputs::ElasticSearch\", :hosts=&gt;[#&lt;URI::Generic:0x2fec3fe6 URL://127.0.0.1:9200&gt;]}\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:26,312][INFO ][logstash.pipeline        ] Starting pipeline {\"id\"=&gt;\"main\", \"pipeline.workers\"=&gt;4, \"pipeline.batch.size\"=&gt;125, \"pipeline.batch.delay\"=&gt;5, \"pipeline.max_inflight\"=&gt;500}\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:27,226][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=&gt;\"0.0.0.0:5044\"}\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:27,319][INFO ][logstash.pipeline        ] Pipeline main started\n</div></li><li><div class=\"code-word\">[2020-10-12T14:12:27,422][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=&gt;9600}\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"886\">\n                      根据控制台输出的日志，我们知道 Logstash\n                      已经正常启动。Elasticsearch 的数据实现可视化就需要结合\n                      Kibana 提供前端的页面视图，你可以在 Kibana\n                      页面进行搜索，使得结果变成图表可视化。\n                    </p>\n                    <h4 data-nodeid=\"887\">Kibana 的安装与使用</h4>\n                    <p data-nodeid=\"888\">\n                      介绍完 Elasticsearch 和 Logstash，下面我们再来了解下\n                      Kibana 的相关概念。Kibana 用于搜索、分析和可视化存储在\n                      Elasticsearch 指标中的日志数据，是一个 Web 网页。Kibana\n                      利用 Elasticsearch 的 REST 接口来检索数据，调用\n                      Elasticsearch\n                      存储的数据，将其可视化。它不仅允许用户自定义视图，还支持以特殊的方式查询和过滤数据。\n                    </p>\n                    <p data-nodeid=\"889\">\n                      Kibana 的安装比较简单，基于 Docker 安装即可：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">docker run --name kibana -e ELASTICSEARCH_URL=http:<span class=\"hljs-comment\">//127.0.0.1:9200 -p 5601:5601 -d kibana:5.6.9</span>\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"891\">\n                      我们在启动命令中指定了 ELASTICSEARCH\n                      的环境变量，就是本地的<code\n                        data-backticks=\"1\"\n                        data-nodeid=\"993\"\n                        >127.0.0.1:9200</code\n                      >。\n                    </p>\n                    <h4 data-nodeid=\"892\">Filebeat 的安装与使用</h4>\n                    <p data-nodeid=\"893\">\n                      ELKB 中的 Filebeat 是最后研发的，并剥离出 Logstash\n                      的数据转发功能。<strong data-nodeid=\"1001\"\n                        >Filebeat 基于 Go\n                        语言开发，是用于转发和集中日志数据的轻量级传送工具</strong\n                      >。通过配置\n                      Filebeat，我们可以监听日志文件或位置、收集日志事件，并将这些文件转发到\n                      Logstash、Kafka、Redis 等，当然也可以直接转发到\n                      Elasticsearch 进行索引。\n                    </p>\n                    <p data-nodeid=\"894\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/B6/CgqCHl-WrwmAbLLsAAEIOMM6eEI271.png\"\n                        alt=\"Drawing 4.png\"\n                        data-nodeid=\"1004\"\n                      />\n                    </p>\n                    <div data-nodeid=\"895\">\n                      <p style=\"text-align: center\">Filebeat 工作原理图</p>\n                    </div>\n                    <p data-nodeid=\"896\">\n                      下面我们就按照如下命令开始安装和配置 Filebeat：\n                    </p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"powershell\"><ol><li><div class=\"code-word\"><span class=\"hljs-comment\"># 下载 filebeat</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-variable\">$</span> <span class=\"hljs-built_in\">wget</span> https://artifacts.elastic.co/downloads/beats/filebeat/filebeat<span class=\"hljs-literal\">-5</span>.<span class=\"hljs-number\">4.3</span><span class=\"hljs-literal\">-linux</span><span class=\"hljs-literal\">-x86_64</span>.tar.gz\n</div></li><li><div class=\"code-word\"><span class=\"hljs-variable\">$</span> tar <span class=\"hljs-literal\">-zxvf</span> filebeat<span class=\"hljs-literal\">-5</span>.<span class=\"hljs-number\">4.3</span><span class=\"hljs-literal\">-linux</span><span class=\"hljs-literal\">-x86_64</span>.tar.gz\n</div></li><li><div class=\"code-word\"><span class=\"hljs-variable\">$</span> <span class=\"hljs-built_in\">mv</span> filebeat<span class=\"hljs-literal\">-5</span>.<span class=\"hljs-number\">4.3</span><span class=\"hljs-literal\">-linux</span><span class=\"hljs-literal\">-x86_64</span> filebeat\n</div></li><li><div class=\"code-word\"><span class=\"hljs-comment\"># 进入目录</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-variable\">$</span> <span class=\"hljs-built_in\">cd</span> filebeat\n</div></li><li><div class=\"code-word\"><span class=\"hljs-comment\"># 配置 filebeat</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-variable\">$</span> vi filebeat/client.yml\n</div></li><li><div class=\"code-word\">filebeat.prospectors:\n</div></li><li><div class=\"code-word\">- input_type: log\n</div></li><li><div class=\"code-word\">  paths:\n</div></li><li><div class=\"code-word\">    - /var/log/*.log\n</div></li><li><div class=\"code-word\">output.logstash:\n</div></li><li><div class=\"code-word\">  hosts: [<span class=\"hljs-string\">\"localhost:5044\"</span>]\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"898\">\n                      在 Filebeat 的配置中，input_type 支持从\n                      Log、Syslog、Stdin、Redis、UDP、Docker、TCP、NetFlow\n                      输入。上述命令配置了从 Log\n                      中读取日志信息，并且配置了只输入 /var/log/\n                      目录下的日志文件；output 将 Filebeat 配置为使用 Logstash\n                      作为输出，并且使用 Logstash 对 Filebeat\n                      收集的数据执行过滤等处理。\n                    </p>\n                    <p data-nodeid=\"899\">配置好之后，我们启动 Filebeat：</p>\n                    <div class=\"course-code-area\">\n                      <div class=\"copy-btn\">\n                        <div class=\"copy-icon\"></div>\n                        复制代码\n                      </div>\n                      <pre><code data-language=\"dart\"><ol><li><div class=\"code-word\">$ ./filebeat  -e  -c client.yml\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.764391</span> beat.go:<span class=\"hljs-number\">285</span>: INFO Home path: [/elk/filebeat] Config path: [/elk/filebeat] Data path: [/elk/filebeat/data] Logs path: [/elk/filebeat/logs]\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.764426</span> beat.go:<span class=\"hljs-number\">186</span>: INFO Setup Beat: filebeat; Version: <span class=\"hljs-number\">5.4</span><span class=\"hljs-number\">.3</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.764522</span> logstash.go:<span class=\"hljs-number\">90</span>: INFO Max Retries <span class=\"hljs-keyword\">set</span> to: <span class=\"hljs-number\">3</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.764588</span> outputs.go:<span class=\"hljs-number\">108</span>: INFO Activated logstash <span class=\"hljs-keyword\">as</span> output plugin.\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.764586</span> metrics.go:<span class=\"hljs-number\">23</span>: INFO Metrics logging every <span class=\"hljs-number\">30</span>s\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.764664</span> publish.go:<span class=\"hljs-number\">295</span>: INFO Publisher name: VM_1_14_centos\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.765299</span> <span class=\"hljs-keyword\">async</span>.go:<span class=\"hljs-number\">63</span>: INFO Flush Interval <span class=\"hljs-keyword\">set</span> to: <span class=\"hljs-number\">1</span>s\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.765315</span> <span class=\"hljs-keyword\">async</span>.go:<span class=\"hljs-number\">64</span>: INFO Max Bulk Size <span class=\"hljs-keyword\">set</span> to: <span class=\"hljs-number\">2048</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.765563</span> beat.go:<span class=\"hljs-number\">221</span>: INFO filebeat start running.\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.765592</span> registrar.go:<span class=\"hljs-number\">85</span>: INFO Registry file <span class=\"hljs-keyword\">set</span> to: /elk/filebeat/data/registry\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.765630</span> registrar.go:<span class=\"hljs-number\">106</span>: INFO Loading registrar data from /elk/filebeat/data/registry\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766100</span> registrar.go:<span class=\"hljs-number\">123</span>: INFO States Loaded from registrar: <span class=\"hljs-number\">6</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766136</span> crawler.go:<span class=\"hljs-number\">38</span>: INFO Loading Prospectors: <span class=\"hljs-number\">1</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766209</span> registrar.go:<span class=\"hljs-number\">236</span>: INFO Starting Registrar\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766256</span> <span class=\"hljs-keyword\">sync</span>.go:<span class=\"hljs-number\">41</span>: INFO Start sending events to output\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766291</span> prospector_log.go:<span class=\"hljs-number\">65</span>: INFO Prospector <span class=\"hljs-keyword\">with</span> previous states loaded: <span class=\"hljs-number\">0</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766390</span> prospector.go:<span class=\"hljs-number\">124</span>: INFO Starting prospector of type: log; id: <span class=\"hljs-number\">2536729917787673381</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766422</span> crawler.go:<span class=\"hljs-number\">58</span>: INFO Loading and starting Prospectors completed. Enabled prospectors: <span class=\"hljs-number\">1</span>\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">46</span>:<span class=\"hljs-number\">31.766430</span> spooler.go:<span class=\"hljs-number\">63</span>: INFO Starting spooler: spool_size: <span class=\"hljs-number\">2048</span>; idle_timeout: <span class=\"hljs-number\">5</span>s\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">47</span>:<span class=\"hljs-number\">01.764888</span> metrics.go:<span class=\"hljs-number\">34</span>: INFO No non-zero metrics <span class=\"hljs-keyword\">in</span> the last <span class=\"hljs-number\">30</span>s\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">47</span>:<span class=\"hljs-number\">31.764929</span> metrics.go:<span class=\"hljs-number\">34</span>: INFO No non-zero metrics <span class=\"hljs-keyword\">in</span> the last <span class=\"hljs-number\">30</span>s\n</div></li><li><div class=\"code-word\"><span class=\"hljs-number\">2020</span>/<span class=\"hljs-number\">10</span>/<span class=\"hljs-number\">12</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">48</span>:<span class=\"hljs-number\">01.765134</span> metrics.go:<span class=\"hljs-number\">34</span>: INFO No non-zero metrics <span class=\"hljs-keyword\">in</span> the last <span class=\"hljs-number\">30</span>s\n</div></li></ol></code></pre>\n                    </div>\n                    <p data-nodeid=\"901\">\n                      Filebeat\n                      将启动一个或多个输入日志或文件位置，这些输入将在日志数据指定的位置中查找。除此之外，Filebeat\n                      还会将监听到的数据发送到其预先配置好的指定输出源。\n                    </p>\n                    <h3 data-nodeid=\"902\">ELKB 的使用实践</h3>\n                    <p data-nodeid=\"1643\">\n                      安装好 ELKB 组件之后，我们开始整合这些组件。首先看下 ELKB\n                      收集日志的流程：\n                    </p>\n                    <p data-nodeid=\"1644\" class=\"\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/65/9A/Ciqc1F-bhKiASToRAAC-S76rRng777.png\"\n                        alt=\"Go_微服务36_图（代替换）.png\"\n                        data-nodeid=\"1653\"\n                      />\n                    </p>\n                    <div data-nodeid=\"1645\">\n                      <p style=\"text-align: center\">ELKB 收集日志的流程图</p>\n                    </div>\n\n                    <p data-nodeid=\"905\">\n                      Filebeat 监听应用的日志文件，随后将数据发送给\n                      Logstash；Logstash 会对数据进行过滤和格式化，如 JSON\n                      格式化，之后将处理好的日志数据发送给\n                      Elasticsearch；Elasticsearch 存储并建立搜索的索引；Kibana\n                      则会调用 Elasticsearch\n                      的存储，为用户提供可视化的视图页面。\n                    </p>\n                    <p data-nodeid=\"906\">\n                      我们运行所有的组件之后，首先看下 elasticsearch-head\n                      中的索引变化：\n                    </p>\n                    <p data-nodeid=\"907\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/AB/Ciqc1F-WryuAUHJAAAP7hK4sVTI416.png\"\n                        alt=\"Drawing 6.png\"\n                        data-nodeid=\"1017\"\n                      />\n                    </p>\n                    <div data-nodeid=\"908\">\n                      <p style=\"text-align: center\">\n                        elasticsearch-head 中的索引界面\n                      </p>\n                    </div>\n                    <p data-nodeid=\"909\">\n                      可以看到多了一个<code\n                        data-backticks=\"1\"\n                        data-nodeid=\"1019\"\n                        >filebeat-2020.10.12</code\n                      >的索引，这说明 ELKB 分布式日志收集框架搭建成功。访问\n                      http://localhost:9100，我们来具体看下索引中的具体数据：\n                    </p>\n                    <p data-nodeid=\"910\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/AB/Ciqc1F-WrzWAHy_vABMEnUwlyUg879.png\"\n                        alt=\"Drawing 7.png\"\n                        data-nodeid=\"1023\"\n                      />\n                    </p>\n                    <div data-nodeid=\"911\">\n                      <p style=\"text-align: center\">日志信息截图</p>\n                    </div>\n                    <p data-nodeid=\"912\">\n                      从上面截图可以看到，/var/log/ 目录下的 mysqld.log\n                      文件中产生了新的日志数据，这些数据非常多，我们在生产环境中需要根据实际的业务进行过滤，并处理相应的日志格式。\n                    </p>\n                    <p data-nodeid=\"913\">\n                      <img\n                        src=\"https://s0.lgstatic.com/i/image/M00/63/B6/CgqCHl-Wrz2ACUhmAAsQ22P7Ts4988.png\"\n                        alt=\"Drawing 8.png\"\n                        data-nodeid=\"1027\"\n                      />\n                    </p>\n                    <div data-nodeid=\"914\">\n                      <p style=\"text-align: center\">Kibana 日志界面</p>\n                    </div>\n                    <p data-nodeid=\"915\">\n                      elasticsearch-head 仅仅是一个简单的 Elasticsearch\n                      客户端，为了更加完整地统计和搜索需求，就需要借助于\n                      Kibana，Kibana 具有很强大的分析能力。上面的 Kibana（访问\n                      <a href=\"http://localhost:5601\" data-nodeid=\"1031\"\n                        >http://localhost:5601</a\n                      >）运行截图展示了 Filebeat 监听到的 mysql\n                      日志，图中可以看到这些日志信息。\n                    </p>\n                    <p data-nodeid=\"916\">\n                      基于 Elasticsearch，Kibana\n                      可以友好地展示海量日志的统计视图，并根据结果生成折线图、直方图和饼图等，这里就不一一展示了。\n                    </p>\n                    <h3 data-nodeid=\"917\">小结</h3>\n                    <p data-nodeid=\"918\">\n                      本课时主要介绍了分布式日志采集系统\n                      ELKB。日志主要用来记录离散的事件，包含程序执行到某一点或某一阶段的详细信息。ELKB\n                      很好地解决了微服务架构下，服务实例众多且分散、日志难以收集和分析的问题。限于篇幅，本课时只介绍了\n                      ELKB 的安装和使用，其实 Go 微服务中一般使用日志框架（如\n                      logrus、zap\n                      等），按照一定的格式将日志输出到指定的位置，这里就交给你自行构建一个微服务进行实践了。\n                    </p>\n                    <p data-nodeid=\"919\" class=\"\">\n                      在第 33\n                      课时，我们讲解了使用分布式链路追踪组件来追踪分布式系统调用链路的问题，而本课时所讲的分布式日志框架也是用来解决分布式系统中发生的问题。关于二者的区别，以及使用的场景，你有什么经验和想法？欢迎你在留言区和我分享。\n                    </p>\n            "}